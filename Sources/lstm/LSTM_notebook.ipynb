{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ad01b-feb8-4374-87ac-690c441c14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-loads all imports every time the cell is ran. \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "import cv2\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Sklearn tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Neural Networks\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='ultralytics.yolo.engine.results.Boxes')\n",
    "\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the read-only '../input/' directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from glob import glob as iglob\n",
    "from random import shuffle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed371884-9772-40fe-bc33-a5f60a425ac5",
   "metadata": {},
   "source": [
    "# Data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e348af-a564-42ac-bc91-a00dd6b0a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotations import ANNOTATIONS as annotations\n",
    "ANNO_REGEX = r\"(\\d_[a-zA-Z]+)_([a-zA-Z0-9]+)_([a-zA-Z]+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71cb3d2-35b6-417c-b2c8-0da9882f4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_by_state = {\n",
    "    'Yawning': {},\n",
    "    'Normal': {},\n",
    "}\n",
    "for k, a in annotations.items():\n",
    "    m = re.search(ANNO_REGEX, k)\n",
    "    if not m:\n",
    "        state = 'Yawning' if len(a['yawns']) > 0 else 'Normal'\n",
    "        who = k\n",
    "    else:\n",
    "        who, att, state = m.groups()\n",
    "    if who not in annotation_by_state[state]:\n",
    "        annotation_by_state[state][who] = []\n",
    "    x = a['num'] + a['offset']\n",
    "    y = np.zeros(x, dtype='int32')\n",
    "    for yawn in a['yawns']:\n",
    "        s, e, *_ = yawn\n",
    "        y[s:e] = 1\n",
    "    \n",
    "    new_ann = {\n",
    "        'offset': a['offset'],\n",
    "        'yawns': a['yawns'],\n",
    "        'name': k,\n",
    "        'num': a['num'],\n",
    "        'y': y,\n",
    "        'path': a['path'] + k\n",
    "    }\n",
    "    annotation_by_state[state][who].append(new_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb5acf-2b87-4bbb-9366-5109b66abf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_by_who = {}\n",
    "for k, a in annotations.items():\n",
    "    m = re.search(ANNO_REGEX, k)\n",
    "    if not m:\n",
    "        state = 'Yawning' if len(a['yawns']) > 0 else 'Normal'\n",
    "        who = k\n",
    "    else:\n",
    "        who, att, state = m.groups()\n",
    "    if who not in annotation_by_who:\n",
    "        annotation_by_who[who] = {\n",
    "            'Yawning': [],\n",
    "            'Normal': [],\n",
    "        }\n",
    "    y = np.zeros(a['num'], dtype='int32')\n",
    "    for yawn in a['yawns']:\n",
    "        s, e, *_ = yawn\n",
    "        s -= a['offset']\n",
    "        e -= a['offset']\n",
    "        y[s:e] = 1\n",
    "    \n",
    "    new_ann = {\n",
    "        'offset': a['offset'],\n",
    "        'yawns': a['yawns'],\n",
    "        'name': k,\n",
    "        'num': a['num'],\n",
    "        'y': y,\n",
    "        'path': a['path'] + k + '/Jpg'\n",
    "    }\n",
    "    annotation_by_who[who][state].append(new_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53131259-c19d-4f93-9c17-c430223e6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(list(annotation_by_who.keys()), random_state=91)\n",
    "train, test = train_test_split(train, test_size=0.1, random_state=91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b66f07-c805-49d6-8591-2a4fca025326",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of persons: {len(annotation_by_who.keys())}\")\n",
    "print(f\"Train: {train}\")\n",
    "print(f\"Test: {test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de9b81-88b7-45f1-9484-7bfdc0c8df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import YawningDataModule, SingleSequenceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6da8c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(pl.LightningModule):\n",
    "    '''\n",
    "    Standard PyTorch Lightning module:\n",
    "    https://pytorch-lightning.readthedocs.io/en/latest/lightning_module.html\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 n_features, \n",
    "                 hidden_size, \n",
    "                 seq_len, \n",
    "                 batch_size,\n",
    "                 num_layers, \n",
    "                 dropout, \n",
    "                 learning_rate,\n",
    "                 criterion):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=n_features, \n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, \n",
    "                            dropout=dropout, \n",
    "                            batch_first=True)\n",
    "        \n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 30),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(30, 2),\n",
    "            # nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        self.train_metrics = nn.ModuleDict({\n",
    "            'train_acc': torchmetrics.classification.MulticlassAccuracy(2),\n",
    "            'train_f1': torchmetrics.classification.F1Score(task='multiclass', num_classes=2, average='macro'),\n",
    "            'train_P': torchmetrics.classification.Precision(task='multiclass', num_classes=2, average='macro'),\n",
    "            'train_R': torchmetrics.classification.Recall(task='multiclass', num_classes=2, average='macro'),\n",
    "        })\n",
    "\n",
    "        self.val_metrics = nn.ModuleDict({\n",
    "            'val_acc': torchmetrics.classification.MulticlassAccuracy(2),\n",
    "            'val_f1': torchmetrics.classification.F1Score(task='multiclass', num_classes=2, average='macro'),\n",
    "            'val_P': torchmetrics.classification.Precision(task='multiclass', num_classes=2, average='macro'),\n",
    "            'val_R': torchmetrics.classification.Recall(task='multiclass', num_classes=2, average='macro'),\n",
    "        })\n",
    "\n",
    "        self.test_metrics = nn.ModuleDict({\n",
    "            'test_acc': torchmetrics.classification.MulticlassAccuracy(2),\n",
    "            'test_f1': torchmetrics.classification.F1Score(task='multiclass', num_classes=2, average='macro'),\n",
    "            'test_P': torchmetrics.classification.Precision(task='multiclass', num_classes=2, average='macro'),\n",
    "            'test_R': torchmetrics.classification.Recall(task='multiclass', num_classes=2, average='macro'),\n",
    "        })\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # lstm_out = (batch_size, seq_len, hidden_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        y_pred = self.model(lstm_out[:,-1])\n",
    "        return y_pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        preds = nn.functional.softmax(y_hat, dim=1)\n",
    "        \n",
    "        for k, metric in self.train_metrics.items():\n",
    "            metric(preds, y)\n",
    "            self.log(k, metric, on_step=True, on_epoch=True)\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        preds = nn.functional.softmax(y_hat, dim=1)\n",
    "        \n",
    "        for k, metric in self.val_metrics.items():\n",
    "            metric(preds, y)\n",
    "            self.log(k, metric, on_step=True, on_epoch=True)\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56885fd",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    seq_len = 48,\n",
    "    step = 8,\n",
    "    yawn_thr = 0.5,\n",
    "    batch_size = 32, \n",
    "    criterion = nn.CrossEntropyLoss(), #nn.MSELoss(),\n",
    "    max_epochs = 100,\n",
    "    n_features = 900,\n",
    "    hidden_size = 600,\n",
    "    num_layers = 1,\n",
    "    dropout = 0.2,\n",
    "    learning_rate = 0.001,\n",
    "    yolo_weights = '../yolov8-face/runs/pose/best_yolov8-lite-t-pose-stematt-bifpn-t/weights/best.pt',\n",
    "    num_workers = 12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10035539",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44f258-823a-46d1-a48f-8de9b004fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1)\n",
    "\n",
    "results = []\n",
    "num_folds = 4\n",
    "split_seed = 91\n",
    "\n",
    "for k in range(num_folds):\n",
    "    \n",
    "    # csv_logger = CSVLogger('./', name='lstm', version='1'),\n",
    "    logger = TensorBoardLogger('runs', name=f'yawning_{num_folds}folds_{k}th')\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(dirpath=None, \n",
    "                                          filename='{epoch}_acc-{val_acc:.2f}_f1-{val_f1:.2f}',\n",
    "                                          save_top_k=10, monitor=\"val_f1\", mode='max')\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=parameters['max_epochs'],\n",
    "        logger=logger,\n",
    "        log_every_n_steps=1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "    \n",
    "    model = LSTMClassifier(\n",
    "        n_features = parameters['n_features'],\n",
    "        hidden_size = parameters['hidden_size'],\n",
    "        seq_len = parameters['seq_len'],\n",
    "        batch_size = parameters['batch_size'],\n",
    "        criterion = parameters['criterion'],\n",
    "        num_layers = parameters['num_layers'],\n",
    "        dropout = parameters['dropout'],\n",
    "        learning_rate = parameters['learning_rate']\n",
    "    )\n",
    "    \n",
    "    dm = YawningDataModule(\n",
    "        annotation_by_who,\n",
    "        model = parameters['yolo_weights'],\n",
    "        seq_len = parameters['seq_len'],\n",
    "        step = parameters['step'],\n",
    "        yawn_thr = parameters['yawn_thr'],\n",
    "        batch_size = parameters['batch_size'],\n",
    "        num_workers = parameters['num_workers'],\n",
    "        k = k,\n",
    "        num_folds = num_folds,\n",
    "        split_seed = split_seed,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, dm)\n",
    "    print(f\"Model {k}/{num_folds} trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d44a0c-0aa0-4717-9c50-5cf480588a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier.load_from_checkpoint(\n",
    "    './runs/yawning_4folds_0th/version_0/checkpoints/epoch=98-step=10296.ckpt', \n",
    "    n_features = parameters['n_features'],\n",
    "    hidden_size = parameters['hidden_size'],\n",
    "    seq_len = parameters['seq_len'],\n",
    "    batch_size = parameters['batch_size'],\n",
    "    criterion = parameters['criterion'],\n",
    "    num_layers = parameters['num_layers'],\n",
    "    dropout = parameters['dropout'],\n",
    "    learning_rate = parameters['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bed5b4e-f9c4-4147-a2f5-a81d137b0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4404241-ebdf-43ad-aa3d-66f3b79edd51",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984ff04-24ca-44d5-a98f-86bd5b83f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier.load_from_checkpoint('./runs/yawning_4folds_0th/version_0/checkpoints/epoch=53_acc-val_acc=0.96_f1-val_f1=0.96.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c38451-1e72-4a85-9e39-d84870e37c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a28f01-6c37-429e-9235-95e84bb7baad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
